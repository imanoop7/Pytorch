{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Exercises require PyTorch > 1.10.0\n",
    "print(torch.__version__)\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Overfitting prevention - \n",
    "\n",
    "`Get more data`\tHaving more data gives the model more opportunities to learn patterns, patterns which may be more generalizable to new examples.\n",
    "\n",
    "`Simplify your model`\tIf the current model is already overfitting the training data, it may be too complicated of a model. This means it's learning the patterns of the data too well and isn't able to generalize well to unseen data. One way to simplify a model is to reduce the number of layers it uses or to reduce the number of hidden units in each layer.\n",
    "\n",
    "`Use data augmentation`\tData augmentation manipulates the training data in a way so that's harder for the model to learn as it artificially adds more variety to the data. If a model is able to learn patterns in augmented data, the model may be able to generalize better to unseen data.\n",
    "\n",
    "`Use transfer learning`\tTransfer learning involves leveraging the patterns (also called pretrained weights) one model has learned to use as the foundation for your own task. In our case, we could use one computer vision model pretrained on a large variety of images and then tweak it slightly to be more specialized for food images.\n",
    "\n",
    "`Use dropout layers`\tDropout layers randomly remove connections between hidden layers in neural networks, effectively simplifying a model but also making the remaining connections better. See torch.nn.Dropout() for more.\n",
    "\n",
    "`Use learning rate decay`\tThe idea here is to slowly decrease the learning rate as a model trains. This is akin to reaching for a coin at the back of a couch. The closer you get, the smaller your steps. The same with the learning rate, the closer you get to convergence, the smaller you'll want your weight updates to be.\n",
    "\n",
    "`Use early stopping`\tEarly stopping stops model training before it begins to overfit. As in, say the model's loss has stopped decreasing for the past 10 epochs (this number is arbitrary), you may want to stop the model training here and go with the model weights that had the lowest loss (10 epochs prior).\n",
    "\n",
    "https://www.learnpytorch.io/04_pytorch_custom_datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting Prevention\n",
    "\n",
    "`Add more layers/units to your model`\tIf your model is underfitting, it may not have enough capability to learn the required patterns/weights/representations of the data to be predictive. One way to add more predictive power to your model is to increase the number of hidden layers/units within those layers.\n",
    "\n",
    "`Tweak the learning rate`\tPerhaps your model's learning rate is too high to begin with. And it's trying to update its weights each epoch too much, in turn not learning anything. In this case, you might lower the learning rate and see what happens.\n",
    "\n",
    "`Use transfer learning`\tTransfer learning is capable of preventing overfitting and underfitting. It involves using the patterns from a previously working model and adjusting them to your own problem.\n",
    "\n",
    "`Train for longer`\tSometimes a model just needs more time to learn representations of data. If you find in your smaller experiments your model isn't learning anything, perhaps leaving it train for a more epochs may result in better performance.\n",
    "\n",
    "`Use less regularization`\tPerhaps your model is underfitting because you're trying to prevent overfitting too much. Holding back on regularization techniques can help your model fit the data better.\n",
    "\n",
    "https://www.learnpytorch.io/04_pytorch_custom_datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\pizza_steak_sushi directory exists.\n"
     ]
    }
   ],
   "source": [
    "#loading the data\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it...\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Download pizza, steak, sushi data\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi data...\")\n",
    "        zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"\n",
    "  Walks through dir_path returning its contents.\n",
    "  Args:\n",
    "    dir_path (str or pathlib.Path): target directory\n",
    "\n",
    "  Returns:\n",
    "    A print out of:\n",
    "      number of subdiretories in dir_path\n",
    "      number of images (files) in each subdirectory\n",
    "      name of each subdirectory\n",
    "  \"\"\"\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in 'data\\pizza_steak_sushi'.\n",
      "There are 3 directories and 0 images in 'data\\pizza_steak_sushi\\test'.\n",
      "There are 0 directories and 25 images in 'data\\pizza_steak_sushi\\test\\pizza'.\n",
      "There are 0 directories and 19 images in 'data\\pizza_steak_sushi\\test\\steak'.\n",
      "There are 0 directories and 31 images in 'data\\pizza_steak_sushi\\test\\sushi'.\n",
      "There are 3 directories and 0 images in 'data\\pizza_steak_sushi\\train'.\n",
      "There are 0 directories and 78 images in 'data\\pizza_steak_sushi\\train\\pizza'.\n",
      "There are 0 directories and 75 images in 'data\\pizza_steak_sushi\\train\\steak'.\n",
      "There are 0 directories and 72 images in 'data\\pizza_steak_sushi\\train\\sushi'.\n"
     ]
    }
   ],
   "source": [
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/pizza_steak_sushi/train'),\n",
       " WindowsPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup train and testing path\n",
    "\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the data\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
